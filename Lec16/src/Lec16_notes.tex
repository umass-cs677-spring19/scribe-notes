%\documentstyle[10pt,twoside]{article}
%\documentstyle[twoside]{article}
\documentclass[twoside]{article}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

\usepackage{graphicx}
\usepackage{url}

%
% The following commands sets up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}
\newcommand{\dnl}{\mbox{}\par}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf CMPSCI~677~~~Distributed and Operating Systems
                        \hfill Spring 2019} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Lecturer: #3 \hfill  #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Lecture #1: #2}{Lecture #1: #2}
   \vspace*{4mm}
}

%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
%
\renewcommand{\cite}[1]{[#1]}

% \input{epsf}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{FIGURE-SIZE}{CAPTION}{FILENAME}
\newcommand{\fig}[4]{
            %\vspace{0.2 in}
            \centerline{\includegraphics[scale=#2]{#4}}
            \begin{center}
            Figure \thelecnum.#1:~#3
            \end{center}
    }

% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% Some useful equation alignment commands, borrowed from TeX
\makeatletter
\def\eqalign#1{\,\vcenter{\openup\jot\m@th
  \ialign{\strut\hfil$\displaystyle{##}$&$\displaystyle{{}##}$\hfil
      \crcr#1\crcr}}\,}
\def\eqalignno#1{\displ@y \tabskip\@centering
  \halign to\displaywidth{\hfil$\displaystyle{##}$\tabskip\z@skip
    &$\displaystyle{{}##}$\hfil\tabskip\@centering
    &\llap{$##$}\tabskip\z@skip\crcr
    #1\crcr}}
\def\leqalignno#1{\displ@y \tabskip\@centering
  \halign to\displaywidth{\hfil$\displaystyle{##}$\tabskip\z@skip
    &$\displaystyle{{}##}$\hfil\tabskip\@centering
    &\kern-\displaywidth\rlap{$##$}\tabskip\displaywidth\crcr
    #1\crcr}}
\makeatother

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:



% Some general latex examples and examples making use of the
% macros follow.

\begin{document}

%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{15}{March 28}{Prashant Shenoy}{\textbf{}}

\section{Overview}
This section covers the following topics:

\begin{description}
  \item[Distributed Transactions:] ACID Properties, Concurrency Control, Serializability, Two-Phase Locking
\end{description}

\section{Transactions}

Transactions are used widely in databases as they provide atomicity (all or nothing property). Atomicity is the property in which operations inside a transaction all execute successfully or none of the operations execute. Thus, if a process crashes during a transaction, all operations that happened during that transaction must be undone.

Transactions are usually implemented using locks. Without locks there would be interleaving of operations from two transactions, causing overwrites and inconsistencies. It has to look like all instructions/operations of one transaction are executed at once, while ensuring other external instructions/operations are not executing at the same time. This is especially important in real-world applications such as banking applications.

\subsection{ACID: Most transaction systems will provide the following properties}
\begin{itemize}
\item{Atomicity: All or nothing (all instructions execute or none; cannot have some instructions execute and some do not)}
\item{Consistency: Transaction takes system from one consistent (valid) state to another}
\item{Isolated: Transaction executes as if it is the only transaction in the system. Ensures that the concurrent execution of transactions results in a system state that would be obtained if transactions were executed sequentially (serializability). In reality, there still will be interleaving of instructions but inconsistent interleaving is prevented.}
\item{Durability: Changes are permanent once transaction completes (commits to disk)}
\end{itemize}

\subsection{Transaction Primitives}

BEGIN\_TRANSACTION: Mark the start of a transaction\\
END\_TRANSACTION: Terminate the transaction and try to commit\\
ABORT\_TRANSACTION:  Kill the transaction and restore the old values (undo all the effects of the transaction)\\
READ:  Read data from a file, a table, or otherwise\\
WRITE: Write data to a file, a table, or otherwise\\

\emph{Ex: Airline Reservation}\\
BEGIN\_TXN\\
  if(reserve(NY, Paris) == full) abort\_txn\\
  if(reserve(Paris,Athens) == full) abort\_txn\\
  ...\\
END\_TXN\\


\section{Distributed Transactions}

\textbf{Nested Transactions}

You can nest multiple smaller child transactions inside a bigger parent transaction. These smaller subtransactions all execute atomically. Each subtransaction is operated on two entirely different (independent) databases.

\textbf{Distributed Transactions}

Database itself is distributed across multiple machines (two physically separated parts of the same database). You execute transactions on this distributed database. Internally, when executing a distributed transaction, the system will have subtransactions that will be executed on physically separate parts of the same database.

\subsection{Implementation: Private Workspace}

Whenever a transaction starts, you make a private copy of the entire database and you will operate on your local copy.

\begin{itemize}
\item{If you need to abort, just delete the private copy.}
\item{If you want to commit a transaction, you see what changes were made in the private copy and copy the changes to the original database when transaction completes. Changes become visible to everyone and you cannot undo the changes.}
\end{itemize}

In reality, you don't create a full copy of the database every time. You use copy-on-write (lazy) technique.

\begin{itemize}
\item{Maintain a set of pointers to the same set of underlying data}
\item{When reading data, nothing changes}
\item{When original data or your local copy changes, you start actual copying}
\item{Defer making a copy until the data starts diverging between copies}
\item{You only copy by blocks or record by record}
\end{itemize}


\textbf{Question}: Should you defragment data because you are moving it over?\\
\emph{Answer}: If you have random access, there is no fragmentation since you are accessing fixed size blocks, which will not cause a performance overhead.

\textbf{Question}: Is the data in memory or disk?\\
\emph{Answer}: All data is reflected (write through) onto disk since it is a database and you want to ensure ACID properties.

\textbf{Question}: Will you see consistency issues if you are making changes to private workspaces and the process crashes during write?\\
\emph{Answer}: If you have a problem while you are making changes to private workspace, you simple abort transaction and the original data is not changed.

\textbf{Question}: Can you make private workspace the original?\\
\emph{Answer}: You can but it depends on whether or not another transaction has committed recently that would change the original.

\textbf{Question}: If you have a nested transaction, how will you ensure that if you commit a sub transaction, you don't roll it back?\\
\emph{Answer}: The commit of the subtransaction and the main transaction all have to happen at the same time. If you commit a subtransaction while other subtransactions are going to execute, you can't undo it so you have to commit all the subtransactions when the main transaction commits.


\subsection{Implementation: Write-ahead Log}

No actual full copy of database is made as changes are made directly to the main original database.
\begin{itemize}
\item{There is a main database and a log file. The log file tracks every change you make.}
\item{In-place updates: transaction makes changes directly to all original files/objects}
\item{Write-ahead log: prior to making a change, transaction writes to log on stable storage}
\item{Use logs to undo changes or rerun transactions}
\item{If you want to commit, you just write commit entry to log stating that this transaction is committed.}
\end{itemize}



\section{Concurrency Control}

Both write-ahead log and private workspace can be used in distributed transactions but the two by themselves are not enough to ensure ACID properties.

You want high concurrency in your database by having multiple transactions execute concurrently. However, you don't want to have a global lock of the entire database since queries will be queued and throughput will be low. Locking should only happen if two transactions are accessing the same data. One can achieve atomicity, consistency, and correctness by ensuring data items are accessed in a specific order.

Concurrency control can be implemented in a layered fashion.

\textbf{How does single database concurrency control work internally?}\\
Transaction managers track each transaction in progress. Scheduler grabs fine-grained locks (for individual records or fields) or use timestamps. Data manager will then read and write data either to workspace or actual database after acquiring a lock from scheduler.

\textbf{How does distributed concurrency control work?}\\
There is still one transaction manager. Each disk for the distributed database will have its own scheduler that will lock the individual records of the data on the disk. Multiple schedulers and data managers will communicate with each other to figure out the ordering of lock acquisition and read/writes of data.


\textbf{Question}: Is distributed database sharded or replicated?\\
\emph{Answer}:\\
Sharded: Take all the data and partition it into chunks and keep chunks on different disks. Distributed database falls into this category.\\
Replicated: Keep N copies of the same database


\subsection{Serializability}

There can be multiple scenarios of the interleaving of instructions from different transactions. You have to identify which scenario is valid or invalid.

You know if a scenario is valid if there is at least some sequential execution of transactions that results in one of the known valid states.

You know if a scenario is invalid if there is no sequential execution of transactions that results in the one of the known valid states. Thus, you will reject it as being ILLEGAL or that there is a write-write conflict and the transaction will then have to be aborted.

You want to execute concurrently but prevent ILLEGAL scenarios. Scenarios with arbitrary interleavings will be accepted as being correct if they produce a known valid state.


\subsection{Optimistic Concurrency Control}

The goal of optimistic concurrency control is to maximize the number of transactions executed in parallel to achieve higher throughput but at the same time avoid scenarios that violate serializability.

Implementation:
\begin{itemize}
\item{Run database without use of locks}
\item{Assume most transactions execute on mutually exclusive parts of the database}
\item{When conflicts arise, abort transaction and redo}
\end{itemize}

This type of concurrency control works well most of the time since conflicts are rare. It IS also easily implemented using private workspaces. However, most relational DBs do not use optimistic concurrency control, but instead strive for correctness rather than performance.

Advantages:
\begin{itemize}
\item{No deadlocks!}
\item{Maximum parallelism}
\end{itemize}

Disadvantages:
\begin{itemize}
\item{Rerun transaction if aborts}
\item{Probability of conflict rises at high loads}
\item{Goodput starts to fall due to more aborts}
\end{itemize}


\subsection{Two-phase Locking (Pessimistic Concurrency Control)}
In two-phase locking, the scheduler acquires all necessary locks gradually in a growing phase, and releases locks gradually in shrinking phase. Whenever you want to do an operation on a data item \emph{x}, you see if \emph{x} conflicts with existing locks. If so, the transaction is delayed and you must wait for lock to be released. If not, you are granted a lock on \emph{x} to perform operations on.

The lock is released when the data manager finishes performing all operations on data item \emph{x} for a transaction. There should be no more instructions that use \emph{x} in that transaction after releasing the lock. Once a lock is released, no further locks can be granted for \emph{x}. Cannot acquire and release a lock on a data item multiple times for multiple operations.

Deadlock is possible if you acquire two locks in different order:

TXN 1\\
------------\\
begin\_txn\\
Lock(x)\\
Read(x)\\
Read(y) \rightarrow Blocked...waiting\,for\,TXN\,2\,to\,release\,lock\,on\,y\\
Write(x)  \rightarrow Another\,operation\,on\,x\\
...\\
Release(x)\\
end\_txn\\


TXN 2\\
------------\\
begin\_txn\\
Lock(y)\\
Read(y)\\
Read(x) \rightarrow Blocked...waiting\,for\,TXN\,1\,to\,release\,lock\,on\,x\\
Write(y) \rightarrow Another\,operation\,on\,y\\
...\\
Release(y)\\
end\_txn\\

\emph{NOTE:} In the context of two-phase locking, TXN 1 and TXN 2 cannot release locks after their first reads because a lock cannot be released until all operations on the data item are performed.

\textbf{Strict two-phase locking}: A variant of two-phase locking where all locks are released at once in the end.

\textbf{How do you resolve deadlocks?}\\
You can number your data items 1 through N and acquire locks in monotonically increasing order. For example, if you need a lock on records 1 and 2, you first acquire a lock on 1 before you acquire a lock on 2. Therefore, you scan operations in a transaction and number and order all data items used. Then, you acquire locks corresponsing to these data items in increasing order. This will ensure that no deadlock cycles happen while operating on the data items from multiple transactions at the same time.

\textbf{Question}: Is it possible you can break logic by numbering resources?\\
\emph{Answer}: If you acquire all locks in the beginning and release them at the end, it will not break the logic.

\subsection{Timestamp-based Concurrency Control (Pessimistic)}

Assume every transaction is an event and associate a logical clock with it. Increment timestamp and whenever multiple transactions read or write data, use logical timestamps to figure out if the conflict is a read-write conflict ora write-write conflict

\begin{itemize}
\item{Read-write conflict: out of date read value due to previous write}
\item{Write-write conflict: overwriting previous update}
\end{itemize}

\textbf{How to avoid conflict?}
For every value in the database, keep the last read and write timestamp.
Details of the algorithm are in the slides.


\end{document}